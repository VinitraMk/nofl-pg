{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import models.autoencoder as vae\n",
    "import models.nfl as nfl\n",
    "import models.credence as credence\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from common.utils import sample_hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for showing probability distributions\n",
    "\n",
    "def view_distribution(gt_df, generated_df, colnames, figsize = (15,30)):\n",
    "\n",
    "    # print(X[:,0].shape, generated_df[1][\"X1\"].shape)\n",
    "    # print('true value range', X[:, 0].min(), X[:, 0].max())\n",
    "    # print('gen value range', generated_df[0][\"X1\"].min(), generated_df[0][\"X1\"].max())\n",
    "\n",
    "    #plt.show()\n",
    "    nrows = len(colnames)\n",
    "    size = figsize\n",
    "    fig,ax = plt.subplots(nrows=nrows,ncols=2,figsize=size)\n",
    "\n",
    "    for i,yvar in enumerate(colnames):\n",
    "        sns.kdeplot(gt_df[yvar], ax = ax[i,0], fill = True)\n",
    "        ax[i,0].set_title(f'Observed {yvar}')\n",
    "        sns.kdeplot(generated_df[yvar], ax = ax[i,1], fill = True)\n",
    "        ax[i,1].set_title(f'Generated {yvar}')\n",
    "\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct experiment\n",
    "\n",
    "def use_nfl(gt_df, x_vars, y_vars, out_vars, treat_vars, categorical_vars, num_vars):\n",
    "    nfl_obj = nfl.NFL(\n",
    "        data = gt_df,\n",
    "        outcome_var = out_vars,\n",
    "        treatment_var = treat_vars,\n",
    "        categorical_var = categorical_vars,\n",
    "        numerical_var=x_vars+num_vars\n",
    "    )\n",
    "    sample_params = sample_hyperparameter(['kld_rigidity'], [(0.0,1.0)])\n",
    "    max_epochs = 100\n",
    "    print('\\n\\nHyperparameters')\n",
    "    print('kld rigidity:', sample_params['kld_rigidity'])\n",
    "    print('max epochs', max_epochs, '\\n\\n')\n",
    "    gen_models = nfl_obj.fit(kld_rigidity = sample_params['kld_rigidity'], max_epochs = max_epochs)\n",
    "\n",
    "    # generated samples\n",
    "    generated_df, generated_df_prime = nfl_obj.sample()\n",
    "    generated_df_prime['Y'] = (generated_df_prime['A'] * generated_df_prime['Y1']) + ((1 - generated_df_prime['A']) * generated_df_prime['Y0'])\n",
    "    generated_df_prime['Y_cf'] = (generated_df_prime['A'] * generated_df_prime['Yprime1']) + ((1 - generated_df_prime['A']) * generated_df_prime['Yprime0'])\n",
    "    view_distribution(gt_df, generated_df_prime, y_vars, (10,10))\n",
    "\n",
    "def use_credence(gt_df, x_vars, y_vars, out_vars, treat_vars, categorical_vars, num_vars):\n",
    "    cred_obj = credence.Credence(\n",
    "        data = gt_df,\n",
    "        outcome_var = out_vars,\n",
    "        treatment_var = treat_vars,\n",
    "        categorical_var = categorical_vars,\n",
    "        numerical_var=x_vars+num_vars\n",
    "    )\n",
    "    sample_params = sample_hyperparameter(['kld_rigidity'], [(0.0,1.0)])\n",
    "    max_epochs = 100\n",
    "    print('\\n\\nHyperparameters')\n",
    "    print('kld rigidity:', sample_params['kld_rigidity'])\n",
    "    print('max epochs', max_epochs, '\\n\\n')\n",
    "    gen_models = cred_obj.fit(kld_rigidity = sample_params['kld_rigidity'], max_epochs = max_epochs)\n",
    "\n",
    "    # generated samples\n",
    "    generated_df, generated_df_prime = cred_obj.sample()\n",
    "    generated_df_prime['Y'] = (generated_df_prime['A'] * generated_df_prime['Y1']) + ((1 - generated_df_prime['A']) * generated_df_prime['Y0'])\n",
    "    generated_df_prime['Y_cf'] = (generated_df_prime['A'] * generated_df_prime['Yprime1']) + ((1 - generated_df_prime['A']) * generated_df_prime['Yprime0'])\n",
    "    view_distribution(gt_df, generated_df_prime, x_vars, (30,30))\n",
    "    view_distribution(gt_df, generated_df_prime, y_vars, (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4adeb84e9f407d90b35fd039b31408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset:', options=('acic19_linear', 'acic19_polynomial', 'toy'), value='acic19_linear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbba5962b5e44a0ab2c02e9e0c1139ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Framework: ', options=('nfl', 'credence'), value='nfl')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define datasets\n",
    "#w = widgets.IntSlider()\n",
    "datasets = ['acic19_linear', 'acic19_polynomial', 'toy']\n",
    "wd = widgets.Dropdown(\n",
    "    options=datasets,\n",
    "    value='acic19_linear',\n",
    "    description='Dataset:',\n",
    ")\n",
    "frameworks = ['nfl', 'credence']\n",
    "wf = widgets.Dropdown(\n",
    "    options = frameworks,\n",
    "    value = 'nfl', \n",
    "    description = 'Framework: '\n",
    ")\n",
    "display(wd)\n",
    "display(wf)\n",
    "dataset_type = wd.value\n",
    "framework_type = wf.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_jensen_umass_edu/vmuralikrish_umass_edu/.conda/envs/mlprojects/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /work/pi_jensen_umass_edu/vmuralikrish_umass_edu/.co ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/work/pi_jensen_umass_edu/vmuralikrish_umass_edu/.conda/envs/mlprojects/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /work/pi_jensen_umass_edu/vmuralikrish_umass_edu/playground/nofl-pg/lightning_logs/version_25465871/checkpoints exists and is not empty.\n",
      "\n",
      "  | Name      | Type       | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | encoder   | Sequential | 16     | train\n",
      "1 | en_mu     | Linear     | 36     | train\n",
      "2 | en_logvar | Linear     | 36     | train\n",
      "3 | decoder   | Sequential | 80     | train\n",
      "4 | decode_Y  | Linear     | 9      | train\n",
      "-------------------------------------------------\n",
      "177       Trainable params\n",
      "0         Non-trainable params\n",
      "177       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset to be used:  toy\n",
      "Framework to be used:  nfl\n",
      "\n",
      "\n",
      "Hyperparameters\n",
      "kld rigidity: 0.3676026091939607\n",
      "max epochs 100 \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_jensen_umass_edu/vmuralikrish_umass_edu/.conda/envs/mlprojects/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:475: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    }
   ],
   "source": [
    "print('Dataset to be used: ', wd.value)\n",
    "print('Framework to be used: ', wf.value)\n",
    "\n",
    "if wd.value == 'toy':\n",
    "    # generating toy dataset\n",
    "    X = np.random.normal(0, 1, (2000, 5))\n",
    "    Y0 = np.random.normal(np.sum(X,axis=1),1)\n",
    "    T = np.random.binomial(1,0.5,size=(X.shape[0],))\n",
    "    Y1 = Y0**2 + np.random.normal(np.mean(X,axis=1),5)\n",
    "    Y = T*Y1 + (1 - T)*Y0\n",
    "    xnames = ['X%d'%(i) for i in range(X.shape[1])]\n",
    "    ynames = ['Y', 'Y_cf']\n",
    "\n",
    "    gt_df = pd.DataFrame(X, columns=['X%d'%(i) for i in range(X.shape[1])])\n",
    "    gt_df['Y'] = T*Y1 + (1 - T)*Y0\n",
    "    gt_df['T'] = T\n",
    "\n",
    "    if wf.value == 'nfl':\n",
    "        use_nfl(gt_df, xnames, ynames, ['Y'], ['T'], ['T'], ['Y'])\n",
    "    elif wf.value == 'credence':\n",
    "        use_credence(gt_df, xnames, ynames, ['Y'], ['T'], ['T'], ['Y'])\n",
    "    else:\n",
    "        SystemExit('Invalid framework type provided!')\n",
    "elif wd.value == 'acic19_linear':\n",
    "    gt_df = pd.read_csv('./data/datasets/acic19_low_dim_1_linear.csv')\n",
    "\n",
    "    x_vars = ['V%d'%(i) for i in range(1,11)]\n",
    "    y_vars = ['Y', 'Y_cf']\n",
    "\n",
    "    if wf.value == 'nfl':\n",
    "        use_nfl(gt_df, x_vars, y_vars, ['Y'], ['A'], ['A'], ['Y'])\n",
    "    elif wf.value == 'credence':\n",
    "        use_credence(gt_df, x_vars, y_vars, ['Y'], ['A'], ['A'], ['Y'])\n",
    "    else:\n",
    "        SystemExit('Invalid framework type provided!')\n",
    "else:\n",
    "    SystemExit('Invalid dataset value provided!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
